{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Web Scrapping</h3>\n",
    "<h4>website-Shiksha.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =time.time()\n",
    "def check_null(data):\n",
    "    if data:\n",
    "        return data.text\n",
    "    else:\n",
    "        return None\n",
    "columns = [\"Sr_no\", \"College Name\", \"Location\", \"Courses offered\", \"Exam accepted\", \"Average Package\", \"Total Fees Range\"]\n",
    "index = 1\n",
    "\n",
    "with open('shiksha.csv', mode='a', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(columns)\n",
    "\n",
    "    page_number = 1  # Initialize page_number\n",
    "    while page_number <= 809:\n",
    "        url = f\"https://www.shiksha.com/search?pn={page_number}&q=list%20of%20colleges\"\n",
    "        # Providing it for accessing the website\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.5790.111 Safari/537.3\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        # checking if connection is there\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            # Extracting \n",
    "            college_name = soup.find_all(class_=\"cd76\") #college_name\n",
    "            courses_offered = soup.find_all(class_=\"_9865 ripple dark\") #courses offered\n",
    "            location = soup.find_all(class_=\"_5588\") #college location\n",
    "            exam_accepted = soup.find_all(class_='_0954')   #exam accepted\n",
    "            container = soup.find_all(\"div\", class_='cd4f _5c64 contentColumn_2') # container it contains both average fees and placement\n",
    "\n",
    "            for name, loc, course, exam, contain in zip(college_name, location, courses_offered, exam_accepted, container):\n",
    "                # Extracting total fees and average packages from container\n",
    "                total_fees = check_null(contain.find_all_next('div', class_=\"dcfd undefined\")[2])\n",
    "                average_package = check_null(contain.find_next('a', class_=\"ripple dark\"))\n",
    "                # Writing in csv file\n",
    "                csv_writer.writerow([index, name.text, loc.text, course.text, exam.text.split(\" \"),\n",
    "                                    average_package, total_fees])\n",
    "                index += 1\n",
    "\n",
    "            page_number += 1\n",
    "      \n",
    "        else:\n",
    "            print(\"Failed to access the website:\", response.status_code)\n",
    "            break\n",
    "end = time.time()\n",
    "execution_time = end - start\n",
    "print(f\"Execution time: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"shiksha.csv\")\n",
    "df.drop_duplicates(subset=['College Name'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sr_no               24210\n",
       "College Name        24210\n",
       "Location            24210\n",
       "Courses offered     24210\n",
       "Exam accepted       24210\n",
       "Average Package      7518\n",
       "Total Fees Range    24210\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12112.276043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6993.491555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6056.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12112.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18168.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24227.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sr_no\n",
       "count  24210.000000\n",
       "mean   12112.276043\n",
       "std     6993.491555\n",
       "min        1.000000\n",
       "25%     6056.250000\n",
       "50%    12112.500000\n",
       "75%    18168.750000\n",
       "max    24227.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Uploading data to hdfs using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SPARK_IP\"]=\"10.0.2.15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"webscraping\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df=spark.read.csv(\"/home/hdoop/Downloads/college_dunia.csv\",inferSchema=True,header=True)\n",
    "    new_df=df.dropDuplicates()\n",
    "    new_df.write.format(\"csv\").save('hdfs://localhost:9000/web_scraper/shiksha_scrapped_data.csv',header=True,inferschema=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
